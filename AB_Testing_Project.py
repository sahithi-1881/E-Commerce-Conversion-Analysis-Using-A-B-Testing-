# -*- coding: utf-8 -*-
"""A/B Testing Project .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UychQPJu0AqTwsnemq565M9owb3WYTTF
"""

# Step 1: Import Required Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency, ttest_ind
from statsmodels.stats.proportion import proportions_ztest

# Load dataset
df = pd.read_csv('speakers_sales_conversion.csv')

# Quick look
df.head()

# Basic cleaning: handle missing values, correct dtypes

df['variant_group'] = df['variant_group'].astype('category')
df['conversion_flag'] = df['conversion_flag'].fillna(0).astype(int)

# Check distribution of landing page variants and conversions

df['variant_group'].value_counts()

df['conversion_flag'].value_counts()

# Step 4: Visualize Sessions per Variant


sns.countplot(x='variant_group', data=df)
plt.title('Sessions per Landing Page Variant')
plt.show()

# Conversion rates by device and variant

pivot = pd.pivot_table(
    df,
    values='conversion_flag',
    index='variant_group',
    columns='device_type',
    aggfunc='mean',
    observed=True )

pivot.plot(kind='bar')
plt.title('Conversion Rate by Variant and Device')
plt.ylabel('Conversion Rate')
plt.show()

# Prepare contingency table for chi-squared test
contingency = pd.crosstab(df['variant_group'], df['conversion_flag'])
chi2, p, dof, expected = chi2_contingency(contingency)
print(f"Chi-squared test p-value: {p:.4f}")
if p < 0.05:
    print("Significant difference in conversion rates between variants.")
else:
    print("No significant difference detected.")

# Contingency table (observed counts)
contingency = pd.crosstab(df['variant_group'], df['conversion_flag'])
print("Observed conversion counts:\n")
print(contingency)

sns.heatmap(contingency, annot=True, fmt='d', cmap='Blues')
plt.title('Observed Conversion Counts')
plt.xlabel('Conversion Flag (0 = No, 1 = Yes)')
plt.ylabel('Variant Group')
plt.show()

from scipy.stats import chi2_contingency

# Get expected counts
chi2, p, dof, expected = chi2_contingency(contingency)
expected_df = pd.DataFrame(expected,
                           index=contingency.index,
                           columns=contingency.columns)
print("\nExpected conversion counts (if no difference between variants):\n")
print(expected_df.round(2))

sns.heatmap(expected_df, annot=True, fmt='.1f', cmap='Oranges')
plt.title('Expected Conversion Counts (Under Null Hypothesis)')
plt.xlabel('Conversion Flag (0 = No, 1 = Yes)')
plt.ylabel('Variant Group')
plt.show()

difference = contingency - expected_df
sns.heatmap(difference, annot=True, fmt='.1f', center=0, cmap='coolwarm')
plt.title('Difference: Observed - Expected')
plt.xlabel('Conversion Flag')
plt.ylabel('Variant Group')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Calculate conversion rate per variant
conversion_rates = df.groupby('variant_group', observed=True)['conversion_flag'].mean().reset_index()

# Calculate counts for annotation
conversion_counts = df.groupby('variant_group', observed= True)['conversion_flag'].agg(['sum','count']).reset_index()
conversion_rates = pd.merge(conversion_rates, conversion_counts, on='variant_group')

# Print conversion rates
print(conversion_rates[['variant_group', 'conversion_flag', 'sum', 'count']])

# Bar plot
plt.figure(figsize=(7,5))
sns.barplot(
    x='variant_group',
    y='conversion_flag',
    hue='variant_group',
    data=conversion_rates,
    palette='Set2',
    legend=False  # hides the duplicate legend
)

plt.title('Conversion Rate by Landing Page Variant')
plt.ylabel('Conversion Rate')
plt.xlabel('Variant Group')
for index, row in conversion_rates.iterrows():
    plt.text(index, row.conversion_flag + 0.01, f"{row.conversion_flag:.2%}", ha='center', va='bottom')
plt.ylim(0, conversion_rates['conversion_flag'].max() + 0.05)
plt.tight_layout()
plt.show()

# Step 9: Pairwise Z-Test for Proportions

import itertools

# Get conversion counts for each variant
variant_stats = conversion_rates.set_index('variant_group')[['sum', 'count']].to_dict('index')
variants = conversion_rates['variant_group'].tolist()

# Pairwise comparisons
for v1, v2 in itertools.combinations(variants, 2):
    count = np.array([variant_stats[v1]['sum'], variant_stats[v2]['sum']])
    nobs = np.array([variant_stats[v1]['count'], variant_stats[v2]['count']])
    stat, pval = proportions_ztest(count, nobs)
    print(f"Comparison: {v1} vs {v2}")
    print(f"  z-statistic: {stat:.3f}, p-value: {pval:.4f}")
    if pval < 0.05:
        print("  Statistically significant difference!\n")
    else:
        print("  No significant difference.\n")

# Step 10: Segmented Analysis by Age, Device, and Traffic Source
age_variant = df.groupby(['variant_group', 'demographic_age_group'], observed=True)['conversion_flag'].mean().reset_index()
plt.figure(figsize=(9,5))
sns.barplot(data=age_variant, x='variant_group', y='conversion_flag', hue='demographic_age_group')
plt.title('Conversion Rate by Variant and Age Group')
plt.ylabel('Conversion Rate')
plt.xlabel('Variant Group')
plt.legend(title='Age Group')
plt.tight_layout()
plt.show()

device_variant = df.groupby(['variant_group', 'device_type'], observed=True)['conversion_flag'].mean().reset_index()
plt.figure(figsize=(9,5))
sns.barplot(data=device_variant, x='variant_group', y='conversion_flag', hue='device_type')
plt.title('Conversion Rate by Variant and Device Type')
plt.ylabel('Conversion Rate')
plt.xlabel('Variant Group')
plt.legend(title='Device Type')
plt.tight_layout()
plt.show()

traffic_variant = df.groupby(['variant_group', 'traffic_source'], observed=True)['conversion_flag'].mean().reset_index()
plt.figure(figsize=(10,5))
sns.barplot(data=traffic_variant, x='variant_group', y='conversion_flag', hue='traffic_source')
plt.title('Conversion Rate by Variant and Traffic Source')
plt.ylabel('Conversion Rate')
plt.xlabel('Variant Group')
plt.legend(title='Traffic Source')
plt.tight_layout()
plt.show()

# Step 11: Impact of Coupons on Conversion

sns.barplot(x='coupon_applied', y='conversion_flag', hue='variant_group', data=df)
plt.title('Conversion Rate by Coupon Use and Variant')
plt.ylabel('Conversion Rate')
plt.show()

# Engagement Metrics
# Average time spent and pages visited by conversion
sns.boxplot(x='conversion_flag', y='time_spent', data=df)
plt.title('Time Spent by Conversion Outcome')
plt.show()

sns.boxplot(x='conversion_flag', y='pages_visited', data=df)
plt.title('Pages Visited by Conversion Outcome')
plt.show()

# Revenue per session by variant (for sessions with purchase)
df_purchases = df[df['conversion_type'] == 'Purchase']
sns.barplot(x='variant_group', y='revenue_$', data=df_purchases)
plt.title('Average Revenue per Purchase by Variant')
plt.show()

!pip install duckdb

import duckdb

# Register your dataframe as a table in DuckDB
con = duckdb.connect()
con.register('df', df)

query = """
SELECT
    variant_group,
    COUNT(*) AS sessions,
    SUM(conversion_flag) AS conversions,
    ROUND(AVG(conversion_flag)*100, 2) AS conversion_rate_pct
FROM df
GROUP BY variant_group
ORDER BY conversion_rate_pct DESC
"""

sql_result = con.execute(query).df()
print(sql_result)

query2 = """
SELECT
    variant_group,
    device_type,
    COUNT(*) AS sessions,
    SUM(conversion_flag) AS conversions,
    ROUND(AVG(conversion_flag)*100, 2) AS conversion_rate_pct
FROM df
GROUP BY variant_group, device_type
ORDER BY variant_group, conversion_rate_pct DESC
"""

sql_result2 = con.execute(query2).df()
print(sql_result2)

sql_result.to_csv('conversion_rate_by_variant.csv', index=False)
sql_result2.to_csv('conversion_rate_by_variant_device.csv', index=False)

df.to_csv('ab_test_full_cleaned.csv', index=False)

age_variant.to_csv('conversion_by_age.csv', index=False)
device_variant.to_csv('conversion_by_device.csv', index=False)
traffic_variant.to_csv('conversion_by_traffic.csv', index=False)

